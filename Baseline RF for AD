import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score
import xgboost as xgb

# Load the dataset
file_path = r"C:\Users\brand\Desktop\PyCharm Community Edition 2024.3\Biomarkers\AD_combined_filtered_species.csv"
AD_combined_filtered = pd.read_csv(file_path)


# Define features (X) and target (y)
X = AD_combined_filtered.drop(columns=['label', 'SubjectID', 'Source'])  # Drop target and unnecessary columns
y = AD_combined_filtered['label']  # Target column


# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)
print("Class distribution after SMOTE:\n", pd.Series(y_train_sm).value_counts())

# Train a RandomForest baseline model
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train_sm, y_train_sm)
y_pred = rf_classifier.predict(X_test)

# Evaluate model performance
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score
import xgboost as xgb

# Load the dataset
file_path = r"C:\Users\brand\Desktop\PyCharm Community Edition 2024.3\Biomarkers\AD_combined_filtered_species.csv"
AD_combined_filtered = pd.read_csv(file_path)

# Display the rows of the dataset
print(AD_combined_filtered.head(30))
print("Columns:", AD_combined_filtered.columns)
print("Label distribution:\n", AD_combined_filtered['label'].value_counts())

# Define features (X) and target (y)
X = AD_combined_filtered.drop(columns=['label', 'SubjectID', 'Source'])  # Drop target and unnecessary columns
y = AD_combined_filtered['label']  # Target column

# Check feature data types and preview
print("Feature data types:\n", X.dtypes)
print("Feature preview:\n", X.head())

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)
print("Class distribution after SMOTE:\n", pd.Series(y_train_sm).value_counts())

# Train a RandomForest baseline model
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train_sm, y_train_sm)
y_pred = rf_classifier.predict(X_test)

# Evaluate model performance
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Identify top 10 important bacteria across all data
feature_importances = rf_classifier.feature_importances_
feature_names = X.columns
importance_df = pd.DataFrame({"Feature": feature_names, "Importance": feature_importances})
importance_df = importance_df.sort_values(by="Importance", ascending=False)


# Print top 10 important features
print("Most Important Features (Bacteria):")
print(importance_df.head(10))
